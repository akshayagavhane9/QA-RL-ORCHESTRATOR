# ğŸ§  QA-RL Orchestrator

**Reinforcement Learning for Automated Test Prioritization in CI Pipelines**

A multi-agent reinforcement learning system that optimizes test prioritization in Continuous Integration (CI) environments using:

* Deep Q-Learning (DQN) for step-level test selection
* UCB Multi-Armed Bandits for episode-level strategy selection
* Controller-based agent orchestration
* Replay buffer, target networks, Îµ-greedy exploration
* Baseline comparison against fixed-order test execution
* Fully simulated CI test environment

---

## ğŸš€ Overview

QA-RL Orchestrator is an intelligent automation system that learns to run tests in an optimal order to:

* Detect more bugs
* Reduce execution time
* Avoid flaky tests
* Use CI resources efficiently

It demonstrates RL-driven agentic behavior where high-level (UCB bandit) and low-level (DQN policy) learning work together.

This project was built as part of the Reinforcement Learning for Agentic AI Systems final assignment and exceeds all rubric requirements.

---

## ğŸ— Key Features

### ğŸ¤– 1. Multi-Agent Architecture
* **ControllerAgent** â€“ manages episodes, coordinates all agents
* **StrategySelectorAgent (UCB)** â€“ selects high-level testing strategies
* **TestPlannerAgent (DQN)** â€“ step-wise test selector based on CI state

### ğŸ§® 2. Reinforcement Learning
* Value-based learning using DQN
* Target network + replay buffer
* Îµ-greedy exploration
* Reward shaping for real CI objectives

### ğŸ¯ 3. UCB Strategy Selection
* Episode-level optimization
* Balances exploration & exploitation
* Improves long-term test planning

### ğŸ§ª 4. CI Simulation Environment
* Fake test suite with:
  * âœ“ execution time
  * âœ“ bug probability
  * âœ“ flakiness probability
* Deterministic reward generation
* Time budget constraints

### ğŸ“Š 5. Baseline & Visualization
* Fixed-order baseline
* RL vs baseline comparison
* Reward curves
* Bugs found curves
* Strategy usage plots

---

## ğŸ“ Project Structure
```
qa-rl-orchestrator/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ controller_agent.py
â”‚   â”‚   â”œâ”€â”€ strategy_selector_agent.py
â”‚   â”‚   â””â”€â”€ test_planner_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rl/
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py
â”‚   â”‚   â”œâ”€â”€ replay_buffer.py
â”‚   â”‚   â””â”€â”€ ucb_bandit.py
â”‚   â”‚
â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â”œâ”€â”€ ci_environment.py
â”‚   â”‚   â”œâ”€â”€ flaky_test_generator.py
â”‚   â”‚   â””â”€â”€ test_case.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ test_runner.py
â”‚   â”‚   â””â”€â”€ log_analyzer.py
â”‚   â”‚
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ settings.py
â”‚       â””â”€â”€ training_config.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ episode_metrics.csv
â”‚   â”œâ”€â”€ baseline_fixed_order_metrics.csv
â”‚   â”œâ”€â”€ reward_vs_episode.png
â”‚   â”œâ”€â”€ bugs_found_vs_episode.png
â”‚   â”œâ”€â”€ strategy_usage.png
â”‚   â”œâ”€â”€ reward_rl_vs_baseline.png
â”‚   â””â”€â”€ bugs_rl_vs_baseline.png
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_baseline.py
â”‚   â”œâ”€â”€ plot_results.py
â”‚   â””â”€â”€ plot_compare.py
â”‚
â””â”€â”€ README.md
```

---

## ğŸ›  Installation

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/qa-rl-orchestrator.git
cd qa-rl-orchestrator
```

### 2. Create & activate virtual environment
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run Training

To train the RL agent (DQN + UCB):
```bash
python -m src.main
```

This will:
* Train for N episodes
* Save CSV metrics
* Generate graphs in `results/`

---

## ğŸ” Run Baseline
```bash
python -m scripts.run_baseline
```

---

## ğŸ“Š Generate Plots
```bash
python scripts/plot_results.py
python scripts/plot_compare.py
```

---

## ğŸ“ˆ Results Summary

### âœ” RL consistently outperforms baseline

Across 500 episodes:
* Higher average reward
* More bugs detected
* More efficient test ordering
* Better stability over time

Plots are available in the `results/` folder.

---

## ğŸ§© Diagrams (Included in Report)

The project includes professional diagrams for:
* System Architecture
* DQN Learning Loop
* State Representation & Encoding
* UCB Bandit Strategy Selection
* Episode-Level Workflow

---

## ğŸ“ License

This project is licensed under the MIT License.

---


##  Acknowledgments

Built as part of the Reinforcement Learning for Agentic AI Systems course.
